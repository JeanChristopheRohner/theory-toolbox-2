<!DOCTYPE html>
<html>


<title>Theory Toolbox 2</title>,
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


<!-- Styles -->

<style>
    
    html,body,h1,h2,h3,h4,h5 {font-family:"Lato", sans-serif}
    .mySlides {display:none}
    .w3-tag, .fa {cursor:pointer}
    .w3-tag {height:15px;width:15px;padding:0;margin-top:6px} 
    
    .w3-container {line-height: 150%;} 
    h3 {padding-top: 20px;}
    h4 {padding-top: 10px;} 
    
    incode {
        font-family: Consolas, Menlo, "courier new";
        color: rgb(0, 0, 0);
        background-color: rgb(224, 232, 234);
        padding: 2px;
        font-size: 90%;
    }
    
    code {
        font-family: Consolas, Menlo, "courier new";
        color: rgb(0, 0, 0);
        background-color: rgb(224, 224, 224);
        border:solid;
        border-color: black;
        border-width: 1px;
        padding: 2px;
        font-size: 70%;
        display:block; 
        white-space:pre-wrap
    }

    symbolic {
        font-family: "Georgia", Times, serif;
        /* font-weight: bold; */
        white-space: nowrap;
    }

    .zoom {
        transition: transform .2s;
    }

    .zoom:hover {
        -ms-transform: scale(1.3); /* IE 9 */
        -webkit-transform: scale(1.3); /* Safari 3-8 */
        transform: scale(1.3); 
    }
    /* Använd med <div class=zoom><div> */

</style>


<body>


<!-- Links on top -->

    <div class="w3-top">
        <div class="w3-row w3-large w3-blue-grey">
        <div class="w3-col s3">
            <a href="#" class="w3-button w3-block">Home</a>
        </div>
        <div class="w3-col s3">
            <a href="#abstract" class="w3-button w3-block">Abstract</a>
        </div>
        <div class="w3-col s3">
            <a href="#writtenDoc" class="w3-button w3-block">Docs</a>
        </div>
        <div class="w3-col s3">
            <a href="https://github.com/JeanChristopheRohner/theory-toolbox-2" target="_blank" class="w3-button w3-block"><i class="fa fa-github w3-margin-right"></i>GitHub Repo</a>
        </div>
        </div>
    </div>


<!-- Content -->


<div class="w3-content" style="max-width:1100px;margin-top:40px;margin-bottom:80px">
  

    <div class="w3-container">
        
        <p>Wellcome! Here you will find information about logic programming for theory representation and scientific inference in psychology, including the written documentation
            for Theory Toolbox 2. Check out the video below or the abstract to get an introduction!
        </p>

        <div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/503833989?title=0&byline=0&portrait=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>
        
    </div>

    <!-- Abstract -->

    <div class="w3-row w3-container"  id="abstract">
        <div class="w3-center w3-padding-64">
            <span class="w3-xlarge w3-bottombar w3-border-dark-grey w3-padding-16">Abstract</span>
        </div>
        <div class="w3-col l3 m6 w3-red w3-container w3-padding-16 w3">
            <h5>Build Explicit and Expressive Theories in First Order Predicate Logic</h5>
            <p style="font-size: 100%;">
                A logic program can represent both the qualitative and quantitative components of a theory in 
                first order predicate logic, one of the most powerful formal languages. Such a representation 
                includes any background assumptions, the meaning of events, and how events are qualitatively and 
                quantitatively related. In fact, any currently known computation can be expressed in a
                logic program (we use Prolog which is Turing complete). <br><br><br>
            </p>
        </div>
        <div class="w3-col l3 m6 w3-blue w3-container w3-padding-16">
            <h5>Use Theories to Deduce Conclusions and Explain These Conclusions as Proofs</h5>
            <p style="font-size: 100%;">
                From a theory program it is possible to use an algorithm to derive valid conclusions, i.e. conclusions
                that have to be true if the premises in the theory are true. Such conclusions come in the form of 
                semantic information and/or quantitative information. Theory Toolbox 2 also explains why a certain 
                conclusions is entailed by a theory by showing all the inferential steps that lead up to the conclusion,
                including any steps that involve numerical computations.<br><br>
            </p>
        </div>
        <div class="w3-col l3 m6 w3-blue-grey w3-container w3-padding-16">
            <h5>Find Unique or Symbolic Solutions to the Equations in a Theory</h5>
            <p style="font-size: 100%;">
                When the system of equations in a theory has a unique solution, this solution is shown in any conclusions and proofs
                that are derived from the theory. In case there are multiple unknowns, it is also possible to perform a search for a 
                unique solution that miximizes or minimizes a certain variable. And if there are no unique solutions at all, 
                Theory Toolbox 2 shows a proof with a symbolic solution.<br><br><br><br>
            </p>
        </div>
        <div class="w3-col l3 m6 w3-teal w3-container w3-padding-16 w3">
            <h5>Use Rational Criteria to Evaluate Theories and Compare Them to Other Theories</h5>
            <p style="font-size: 100%;">
                Using rational criteria for theory evaluation is an important part of theory evaluation, in addition to data collection and analysis. 
                With Theory Toolbox 2 it is possible to check whether a theory is internally coherent (not self contradictory),
                measure how general it is (how falsifiable it is) and check whether it subsumes another theory (it contains everything that 
                another theory contains). <br><br><br>
            </p>
        </div>
    </div>
  

    <!-- Documentation -->
    
    <div class="w3-center w3-padding-64" id="writtenDoc">
        <span class="w3-xlarge w3-bottombar w3-border-dark-grey w3-padding-16">Documentation</span>
    </div>
    
    <div class="w3-container">

        <p>
            Below you can find a written guide to logic programming, theory representation and inference with Theory Toolbox. 
            <a href="https://doi.org/10.1016/j.newideapsych.2020.100838" target="_blank">Rohner and Kjellerstrand (2021)</a> 
            contains a theoretical discussion of theory representation in psychology; this web page contains
            the documentation for Theory Toolbox 2.
        </p>
        
        <!-- Overview -->

        <h3>1. Overview</h3>
        <p> 
            <ul>
                <li>Section 2 explains how to install SWI Prolog and Theory Toolbox 2, and how to run some examples.</li>
                <li>Section 3 gives a quick introduction to logic programming.</li>
                <li>Section 4 explains some basic principles for designing scientific theories.</li>
                <li>Section 5 discusses the advantages of logic programming with respect to theory representation.</li>
                <li>Section 6 shows how to use Theory Toolbox 2 for inference, explanation and theory evaluation.</li>
            </ul>
        </p>


        <!-- Installation and Setup -->

        <h3>2. Installation and Setup</h3>
        <p>
            To run Theory Toolbox 2 you need SWI Prolog (Wielemaker et al., 2011). The sections below explain all the steps 
            necessary to get up an running.
        </p>
        <h4>2.1. Installation</h4>
        <p>
            It is possible to run SWI-Prolog from Terminal on Mac or the command line in Windows. 
            However, using Visual Studio Code is very handy: 
            It has built in GitHub support and you can define user snippets for different logical symbols.
            To setup everything to work with Visual Studio Code follow these steps:
            <ol>
                <li>
                    Download and install <a href="https://www.swi-prolog.org/Download.html" target="_blank">SWI Prolog</a>.
                </li>
                <li>
                    Download and install <a href="https://code.visualstudio.com/download" target="_blank">Visual Studio Code</a>.
                </li>
                <li>
                    Install the VSC Prolog extension
                    <ul>
                        <li>
                            Start Visual Studio Code and click the extensions symbol in the side bar on the far left (the symbol with four squares).
                        </li>
                        <li>
                            Search for the VSC Prolog extension and install it.
                        </li>
                    </ul>
                </li>
                <li>Download the Theory Toolbox 2 repository
                    <ul>
                        <li>
                            Using your web browser navigate to the <a href="https://github.com/JeanChristopheRohner/theory-toolbox-2" target="_blank">theory-toolbox-2 repository</a>.     
                        </li>
                        <li>
                            Click the green Code button and chose Download ZIP
                        </li>
                        <li>
                            Unpack the folder somewhere on you hard drive
                        </li>
                        <li>
                            In Visual Studio Code, click the File menu, choose Open Folder, and open the theory-toolbox-2 folder.
                        </li>
                    </ul>
                </li>
                <li>Load an example
                    <ul>
                        <li>
                            In the folder structure to the left double click an example, e.g. 
                            substanceMisuseExample.pl.
                        </li>
                        <li>
                            Click the menu View and chose Command Palette... Type <incode>prolog load document</incode> and hit return. 
                            Now a terminal should appear.
                        </li>
                    </ul>
                </li>
                <li>Run some example queries
                    <ul>
                        <li>
                            Now you should be able to run a query. Next to <incode>?-</incode> type the name of a query, 
                            such as <incode>q3</incode>, followed by a period and hit return.
                        </li>
                    </ul>
                    
                </li>
            </ol>
            If you encounter any problems you may have to correct the path to the Prolog executable in Visual Studio Code. To do so,
            search for swipl on your computer and copy the path to swipl (on mac it is usually <incode>/Applications/SWI-Prolog.app/Contents/MacOS/swipl</incode>; 
            on PC it is usually <incode>C:\Program Files\swipl\bin\swipl.exe</incode>). In Visual Studio Code, go to settings (the cogweel at the far  left)
            chose settings and navigate to the settings for the VSC Prolog extension. Under Prolog Executable Path paste in the path and save.
        </p>

        <h4>2.2. Using Theory Toolbox 2 on Your own Theory</h4>
        <p>
            To use the toolbox on your own theory
            <ol>
                <li>Create a text file (UTF-8 with BOM encoding) and write the following at 
                the top of this file: <incode>:-include('theoryToolbox2.pl').</incode> Your file has to be in the same directory as theoryToolbox2.pl 
                (alternatively you can modify the include directory to point to another directory that contains theoryToolbox2.pl).</li>
                <li>Open the file in Visual Studio Code and run a query (as described under 6 above).</li>
            </ol>
            <p>The include directive</p>
            <ul>
                <li>Enables the use of clpr predicates (explained below).</li>
                <li>Enables the use of symbols from classic logic: <incode>∧</incode>, <incode>∨</incode>, <incode>⇐</incode>, <incode>¬</incode> (in theoryToolbox2.pl 
                    these are defined as operators and term_expansion/2 and goal_expansion/2 are used to replace them with 
                    standard Prolog operators).</li>
                <li>Enables the following Theory Toolbox 2 predicates: provable/3, prove/3, maxValue/4,
                    minValue/4, incoherence/7, falsifiability/3, subsumes/5 (the number 
                    indicates the number of arguments in the predicate).
            </ul>
        </p>


        <!-- Syntax and Semantics of Logic Programs -->

        <h3 id="section3">3. Syntax and Semantics of Logic Programs</h3>
        
        <h4>3.1. Atomic Formulas</h4>
        <p>
            The basic building blocks of a logic program are atomic formulas; these describe properties and relations that involve singular objects or sets of objects. 
            Syntactically an atomic formula consists of a predicate name, written with an initial lower case letter,
            directly followed by a comma delimited list of arguments in parentheses. Some examples of atomic formulas are <incode>human(H)</incode>, 
            <incode>parent(homer, bart)</incode>, <incode>event(H1, like, H2, T, X)</incode>, and <incode>event(john, believe, event(mary, like, john))</incode>. 
            Respectively these can be taken to mean that H is human, that Homer is Bart's parent, that H1 likes H2 at time T with probability X, and that 
            John believes that mary likes him.
        </p>
        <p>
            Each argument in an atomic formula is a term. A term either a constant, a variable or a function.
            <ul>
                <li>
                    A constant denotes a single object; it is written as a string that starts with a lower case 
                    letter or as a number, e.g. <incode>bart</incode>, <incode>cocaine</incode> or <incode>3.14</incode>.
                </li>
                <li>
                    A variable denotes a set of objects; it is written as a string that starts with an uppercase letter,
                    e.g. <incode>X</incode>, <incode>H1</incode>, or <incode>Human</incode>.
                </li>
                <li>
                    A function denotes a relation; it consists of a function name directly followed by a comma delimited list of 
                    arguments in parentheses. Each argument is a term. In the atomic formula <incode>event(H1, believe, event(H2, like, H1))</incode>,
                    the part <incode>event(H2, like, H1)</incode> is a function for example.
                </li>
            </ul>
        </p>
        <p>
            A special kind of atomic formula is a numerical constraint. It consists of an equation written in curly braces (per the clpr module).
            Some examples of legal constraints are:
            <ul>
                <li><incode>{X = 1 + 1}</incode>, meaning X equals one plus one.</li>
                <li><incode>{X = Z * (1 - Y)}</incode>, meaning X equals Z times one minus Y.</li>
                <li><incode>{X =< Y}</incode>, meaning X is less than or equal to Y.</li>
                <li><incode>{X = Y^3}</incode>, meaning X equals Y to the power of 3.</li>
                <li><incode>{X = 4^0.5)</incode>, meaning X equals the square root of 4.</li>
                <li><incode>{X = abs(Y - Z), Y > 3}</incode>, meaning X equals the absolute value of Y minus Z, and that Y is greater than 3.</li>
            </ul>
            For more information about clpr constraints see this <a href="https://www.swi-prolog.org/man/clpqr.html" target="_blank">link.</a>
        </p>

        <h4>3.2. Definite clauses</h4>
        <p>
            A theory program is made up of a set of definite clauses, each ending with a period. A definite clause is an implication with a single non-negated 
            atomic formula in the consequent, and zero or more atomic formulas or numerical constraints in the antecedent. 
            Schematically, <symbolic>C ⇐ A<sub>1</sub> ∧ A<sub>2</sub> ∧ ... ∧ A<sub>n</sub>.</symbolic> , where <symbolic>C</symbolic> is a non negated atomic formula, 
            and where <symbolic>A<sub>i</sub></symbolic> is an atomic formula or a numerical constraint (<symbolic>i = 0, 1, ..., n</symbolic> 
            and <symbolic>n >= 0</symbolic>). In a clause with an empty antecedent, <symbolic>C.</symbolic> ,
            the consequent is provable without additional conditions. In a clause with a non empty antecedent, 
            <symbolic>C ⇐ A<sub>1</sub> ∧ A<sub>2</sub> ∧ ... ∧ A<sub>n</sub>.</symbolic> , <symbolic>C</symbolic> is 
            provable if <symbolic>A<sub>1</sub> ∧ A<sub>2</sub> ∧ ... ∧ A<sub>n</sub></symbolic> is provable. Some examples are 
            given in the program in Figure 1. The first two clauses mean that it is provable that Homer is Bart's parent, 
            and that Abe is Homer's parent. The last clause has the following meaning: For all X, Y and Z, if X is Zs parent and if Z is Ys
            parent, then X is Ys grandparent.
        </p>
        <p>
            <b>Figure 1. A Toy Program with Three Clauses</b>
        </p>
        <p>     
            <img src="figure1.png" style="width:100%">
        </p>
        <p>
            In the antecedent of a clause, atomic formulas and constraints can be combined with conjunction (<symbolic>∧</symbolic>), 
            disjunction (<symbolic>∨</symbolic>) and equality (<symbolic>=</symbolic>). A conjunction 
            <symbolic>A<sub>1</sub> ∧ A<sub>2</sub> ∧ ... ∧ A<sub>n</sub></symbolic> is provable 
            if each <symbolic>A<sub>i</sub></symbolic> is provable (<symbolic>i = 1, 2, ..., n</symbolic>). A disjunction 
            <symbolic>A<sub>1</sub> ∨ A<sub>2</sub> ∨ ... ∨ A<sub>n</sub></symbolic> is provable if at least one <symbolic>A<sub>i</sub></symbolic>
            is provable (<symbolic>i = 1, 2, ..., n</symbolic>). Equality can be used to impose the restriction that two constants have to be equal (techincally equality
            is used to indicate unification; more about that later). Ordinary parentheses are used to indicate precedence as usual.
            Any atom <symbolic>A</symbolic> in the antecedent of a clause can be negated by writing <incode>¬A</incode>, which means that 
            <symbolic>A</symbolic> is not provable; i.e. <symbolic>A</symbolic> is not entailed by the program.
            Note that this is different from saying that <symbolic>A</symbolic> is not the case. That 
            <symbolic>A</symbolic> is not the case has to be indicated explicitly, e.g. with a probability of 0: <incode>p(A, 0).</incode>,
            which means that it <i>is</i> provable that <symbolic>A</symbolic> has a probability of zero.
        </p>
        <p>Clauses with a non empty antecedent usually contain variables, and they therefore describe general relations. 
            For example, <incode>aunt(A, C) ⇐ sister(A, M) ∧ parent(M, C)</incode> means that the aunt relation holds for any
            A, C and M. The scope of a variable is the clause in which it appears. This means that same named variables in a clause have 
        to be instantiated with the same constant (between clauses same named variables can be instantiated with different constants).</p>
        <p>
            Consider another example that mixes qualitative and quantitative relations, shown in Figure 2. In the example we use an event predicate
            with a subject, a verb, an object and a probability value. In addition to stating that h1 is a human, that heroin is an opiate and so on, it also says that,
            among other things, h1 used heroin with a probability of 0.90 and that an opiate causes pleasure
            with probability 0.90. The last clause has the following meaning. For all H, S, X1, X2, X3, it 
            is provable that H uses S with probability X3 if all of the following conditions hold: H is a human,
            H used S with probability X1, S causes pleasure with probability X2, X3 is equal to 
            the product between X1 and X2.
        </p>
        <p><b>Figure 2. A Toy Program that Mixes Qualitative and Quantitative Relations</b></p>
        <p>
            <img src="figure2.png" style="width:100%"> 
        </p>
        <p>
            Before ending this section something needs to be said about the relation between Theory Toolbox 2 and Prolog. Readers who are familiar with 
            Prolog might have noted that our examples do not use standard Prolog syntax (in which comma is used for conjunction and 
            <incode>:-</incode> for implication). But actually, "under the hood", all code <i>is</i> Prolog: Before running a program,
            Theory Toolbox 2 uses term_expansion/2 and goal_expansion/2 to replace <incode>∧</incode> with <incode>,</incode>, <incode>∨</incode> with <incode>;</incode>,
            <incode>¬</incode> with <incode>\+</incode>, and <incode>⇐</incode> with <incode>:-</incode>. So if this is preferred,
            it is possible to write a theory program in pure Prolog and to use Theory Toolbox 2 on this program. Readers who want to know more
            about Prolog can check out the excellent introduction <a href="http://www.learnprolognow.org" target="_blank">Learn Prolog Now</a> by
            Patrick Blackburn, Johan Bos and Kristina Striegnitz. A more advanced text is Markus Triska's 
            <a href="https://www.metalevel.at/prolog" target="_blank">The Power of Prolog</a>.
        </p>


        <!-- Design Principles for Theory Programs -->

        <h3>4. Design Principles for Scientific Theories</h3>
        <p>
            With this background, we can now discuss some general design principles for building 
            actual theory programs. The text below is a brief summary of some of the principles discussed 
            in <a href="https://doi.org/10.1016/j.newideapsych.2020.100838" target="_blank">Rohner and Kjellerstrand (2021)</a>.
        </p>

        <ul>
            <li>
                A scientific theory consists of a set of definite clauses that contain a qualitative and quantitative 
                description of events, relations between events, including any background assumptions on which these relations 
                depend. Every component of a theory a definite clause. Consider the main clauses in the 
                <a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/emotionExample.pl" target="_blank">
                emotion theory</a>. Note, for example, that each emotion is described as an implication, in which the consequent 
                (the probability of the emotion) depends on a set of necessary and sufficient conditions in the antecedent.
            </li>
            <li>
                The clauses in a theory can usually be grouped into background clauses and
                main clauses. Background clauses represent the background assumptions of a theory. Main clauses represent the main 
                relations of a theory. Consider the emotion theory again. The main parts of the theory are the 
                clauses that describe each one of the five emotions; accordingly, these clauses are listed under main clauses. 
                The other clauses, e.g. about what kinds of things people value, which events are congruent with a certain goal, 
                and so on, are background assumptions, so these are listed under background clauses.
            </li>
            <li>
                The constructs (concepts) in a theory can be represented by a five argument event atom. Its components are 
                a subject, a verb, an object, a time frame, and a probability value (but any number of additional arguments,
                such as a place argument, can be added if relevant). By doing so a theory program represents the meaning of constructs.
                Moreover any argument can be a constant, a variable or a function. The emotion theory, for example, contains several such 
                event atoms. Note also that a function is used as the object argument in each emotion clause to distinguish between appraisal and what is appraised.
                In fear, for example, appraisal is about a future goal incongruent event.
            </li>
            <li>
                In addition to the usual symbols of logic, the relations of a theory can be described with a set of 
                equations that relate the probabilities (or other magnitudes) of different events. So in the
                emotion theory, to take an example, the probability of an emotion depends on the probabilities of different appraisal patterns 
                (see the main clauses of the theory).
            </li>
            <li>
                In the clauses of a theory, the domains of all variables should be defined.
                This explicitly states the objects that the theory is about, in terms of a set of necessary and sufficient conditions. 
                For example, in the main 
                clauses of the emotion theory, H1, H2, E and G and so on, are defined to be humans, events, and goals, respectively. 
            </li>
        
        </ul>

        <!-- Advantages of Logic Programming -->

        <h3>5. Advantages of Logic Programming</h3>
        <p>
            This section briefly describes some of the advantages of logic programming. An in depth discussion of these advantages
            can be found in <a href="https://doi.org/10.1016/j.newideapsych.2020.100838" target="_blank">Rohner and Kjellerstrand (2021)</a>.
        </p>
        <ul>
            <li>
                <b>Explicit Background Assumptions.</b> Because first order logic can represent almost any kind of relation,
                it is possible to build a detailed formalization of the background assumptions in a theory. Any prediction <symbolic>C</symbolic> from a theory is 
                then entailed by its main clauses <symbolic>M</symbolic> and its background clauses <symbolic>B</symbolic>; 
                schematically <symbolic>M ∧ B ⊨ C</symbolic>. So if states of affairs are at odds with <symbolic>C</symbolic>, the blame <i>has</i> to fall on 
                either <symbolic>M</symbolic> or <symbolic>B</symbolic>, or both <symbolic>M</symbolic> and <symbolic>B</symbolic>. 
                When (informally) deducing empirical predictions from a natural language representation, in contrast, there is a higher 
                risk that we unwittingly presuppose one or more <symbolic>B</symbolic>s that were never in the theory. So a test of such 
                a prediction becomes ambiguous: If a <symbolic>B</symbolic> wasn't in the theory, an empirical test that assumed this 
                <symbolic>B</symbolic> is not a test of the theory.
            </li>
            <li>
                <b>A Representation of both the Qualitative and Quantitative Parts of a Theory.</b> By using predicates, such as the event predicate, 
                in addition to the usual symbols of logic, is is possible to capture important qualitative information that is usually expressed in natural language. 
                And the possibility to nest an arbitrary number of functions in an atomic formula, increases this expressive power even further. 
                Such qualitative information can be combined with any number of equations that relate probabilities or other quantities. 
                Note also that when the semantic content of events is decomposed into subject, verb, object, time and value arguments,
                is is possible to represent some important relations between the <i>intra</i> event components of <i>different</i> events in a clause.
            </li>
            <li>
                <b>Universal Statements About Well Defined Domains.</b> Scientific theories consist of a set of universal statements that describe 
                relations between <i>all</i> events
                of a certain kind; i.e. they are nomothetic descriptions (Popper, 1972). A powerful feature of first order logic is that is is 
                possible to say that a certain relation holds for all objects in one 
                or more sets <i>and</i> to provide detailed definitions of these sets. This is achieved by using variables and by writing 
                any domain definitions in the antecedent of a clause.
            </li>
            <li>
                <b>Modularity.</b> Another powerful feature of logic programs is that they are modular representations, meaning that: 
                (1) It is possible to add any number of components to a theory without modifying the components that already exist in the theory.
                (2) Adding components to a theory will usually make the theory entail more inforrmation than just the information contained 
                in the added components.
            </li>
            <li>
                <b>Validity.</b> When a theory is represented in a logic program it is possible to use resolution to derive valid conclusions from it.
                A valid conclusion is a conclusion that <i>has</i> to be true if the information in the program is true. Schematically,
                <symbolic>M ∧ B ⊨ C</symbolic>, where <symbolic>M</symbolic> is 
                the set of main clauses, <symbolic>B</symbolic> the set of background clauses, and <symbolic>C</symbolic> the conclusion. So when a theory 
                is a good one one, it can be used to generate accurate predictions and explanations. It goes without saying that this 
                function is relevant whenever a scientific theory is used in an applied setting. And when a theory is pitted against empirical data,
                finding not <symbolic>C</symbolic> must necessarily mean that either <symbolic>M</symbolic> or <symbolic>B</symbolic>, or both 
                <symbolic>M</symbolic> and <symbolic>B</symbolic> are wrong.
            </li>
            <li>
                <b>Rational Theory Evaluation.</b> Because theory programs are formal representations, it is possible to hand them to 
                algorithms that perform basic sanity checks, already before empirical testing. For example, Theory Toolbox has predicates that ckeck whether a theory 
                is internally coherent, how general it is, and if it subsumes one or more other theories. 
            </li>
            <li>
                <b>Collaboration.</b> Theory programs can be uploaded to an online software hosting and version control platform
                such as GitHub. This has the following advantages: (1) Members of a reasearch team can suggest and make changes to the theory online; 
                (2) It is easy to keep track of any changes to the theory; (3) members of the team instantly have the latest version of the theory 
                available on their computer (the local version of the theory is synchronized to the online one); (4) members of the team can instantly
                run queries on the latest version of the theory (e.g. using Theory Toolbox 2).
            </li>
        </ul>


        <!-- Using Theory Toolbox -->

        <h3>6. Using Theory Toolbox 2</h3>
        <p>
            This section is an introductory users guide to the predicates in Theory Toolbox 2. It starts with a general discussion 
            of proof search and then describes each predicate in Theory Toolbox 2.
        </p>
        <p>
            A common feature of the predicates in Theory Toolbox 2 is that they all, in some way or another, 
            deal with the conclusions that are entailed by a theory program. The search for such conclusions starts 
            with a query goal, an atomic formula which may or may not contain variables. If the goal only contains 
            constants, the output is <incode>true</incode> (or <incode>false</incode>), meaning that it is true (or false) 
            that this goal is entailed by the theory program. If the goal contains one or
            more variables, all the variable instantiations that are entailed by the program are shown.
            As an example, suppose the query goal is <incode>grandparent(abe, bart).</incode> , which in relation to Figure 1, 
            means "does the program entail this relation between constants?". In this case the answer would be <incode>true</incode>. 
            The query goal <incode>grandparent(abe, X)</incode>, instead means 
            "for what Xs does this relation hold according to the program?". In this case we get any constants for 
            which the goal holds (is provable); i.e. <incode>X = bart</incode>.
        </p>
        <p>
            So in what cases exactly is a goal provable? In other words, in what cases does a theory program entail a goal? 
            Before explaining this, a basic understanding of unification is necessary, because unification is 
            an essential part of proof search. Unification is about determining if two formulas match or not; 
            syntactically unification is indicated by the equality sign <incode>=</incode>.
            Two formulas unify in the following important conditions:
            <ol>
                <li>Two constants unify if they are the same </li>
                <li>A variable unifies with any kind of term and is instantiated to that term</li>
                <li>Two atomic formulas, or functions, unify if all of these conditions hold:</li>
                <ol type = "a">
                    <li>They have the same name</li>
                    <li>They have the same number of arguments</li>
                    <li>All of their arguments unify</li>
                    <li>Their variables can be instantiated consistently</li>
                </ol>
            </ol>
            So according to rule 1, <incode>bart = bart</incode>, <incode>1 = 1</incode>, and <incode>3.14 = 3.14</incode>. 
            According to rule 2, <incode>X = bart</incode> and <incode>Y = event(john, like, mary)</incode>. And according to
            rule 3 <incode>event(H1, represent, Representation) = event(H1, represent, event(H1, like, H2))</incode>, because both atoms 
            have the same name (<incode>event</incode>), the same number of arguments (3), because <incode>H1 = H1</incode>, 
            because <incode>represent = represent</incode>, and because <incode>Representation = event(H1, like, H2)</incode>. But, according 
            to rule 3d, <incode>foo(X, X) = foo(2, 3)</incode> fails because <incode>X</incode> is first instantiated to 2 and 
            then 2 does not unify with 3.
        </p>
        <p>
            And now we finally get to the conditions for when a goal is provable (without going into technical details).
            A goal is provable in each one of the following cases:
            <ol>
                <li>The goal is true, e.g. as in <incode>{4 = 2 + 2}</incode>, or <incode>{X = 2 + 3, X > 1}</incode></li>
                <li>The goal unifies with the consequent of a clause that has an empty antecedent</li>
                <li>The goal unifies with the consequent of a clause whose antecedent is provable</li>
                <li>The goal unifies with a term in INPUT</li>
            </ol>
            But what does INPUT mean? More about that in the next section.
        </p>
        <h4>6.1. The INPUT argument</h4>
        <p>
            All of the predicates in Theory Toolbox 2 have an argument called INPUT. INPUT is used to temporarily assert anything that is 
            considered provable <i>in addition</i> to the information in a theory program. Because theories should only contain 
            general statements, they are not supposed to be filled will all the particular instances to which they may be applied. 
            For example, a theory about kinship, should not contain clauses about Homer being the parent of Bart and so on (see Figure 1). 
            Such information should be provided in INPUT instead. The theory, per se, should only contain general statements like 
            <incode>grandparent(G, C) ⇐ parent(G, P) ∧ parent(P, C).</incode> . Syntactically, INPUT is a Prolog list, i.e. a comma delimited 
            list of atomic formulas in square brackets. So by writing, for example, 
            <incode>INPUT = [parent(jaqueline, marge), parent(marge, lisa)]</incode>, we declare that these goals are provable 
            in addition to the information in a theory program.
        </p>
        <p>
            Note that all <a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/tree/main/theoryExamples" target="_blank">theory examples</a> 
            contain a commented section INPUT. This is a declaration of what atoms that have to be provided in INPUT in order for 
            all the consequents of a theory to be provable. Providing such a section is not necessary but it is a favour to any third parties that wish
            to use a theory. Practical examples in which INPUT is used follow below.
        </p>

        <h4>6.2. provable/3</h4>
        <p>
            <incode>provable(GOAL, INPUT, RESULT)</incode> queries if <incode>GOAL</incode> is provable given <incode>INPUT</incode> and unifies the result 
            with <incode>RESULT</incode>. In case <incode>GOAL</incode> only contains constans, 
            the output is <incode>true</incode> or <incode>false</incode>. In case <incode>GOAL</incode> contains any variables, 
            <incode>RESULT</incode> is unified with any variable instantiations in <incode>GOAL</incode> that are entailed by the program.
            <ul>
                <li><incode>GOAL</incode> should be an atomic formula with constants, variables or functions as arguments. </li>
                <li><incode>INPUT</incode> should be a list of zero or more atomic formulas. </li>
            </ul>
        </p>
        <p>
            <incode>showProvable(RESULT)</incode> prints the result obtained from <incode>provable(GOAL, INPUT, RESULT)</incode> to the console.
        </p>
        <p>
            Figure 3 shows two queries with provable/3 and the associated output predicate showProvable/1. The underscores in the goal are anonymous variables.
            Using an anonymous variable for an argument in the goal is equivalent to saying "Whatever the theory entails for this argument and predicate.".
            Note, for example, that <incode>aunt(selma, lisa)</incode> holds because the information that leads up to this conclusion is a combination 
            of the clauses in the program and the information in <incode>INPUT</incode> (see the discussion in the previous section).
        </p>
        <p>
            <b>Figure 3. provable/3 Used on a Toy Example</b>
        </p>
        <p>
            <img src="figure3.png" style="width:100%">
        </p>
        <p>
            Figure 4 shows a query on the <a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/substanceMisuseExample.pl" target="_blank">
            substance misuse example</a>. The query goal means "the probability that somebody experiences harm at time 6"
            (value was the last argument in event). The line <incode>misuse(MISUSE)</incode> unifies <incode>MISUSE</incode> with any 
            misuse behavior in the theory (e.g. <incode>useHeroin</incode>). This variable is then used in <incode>INPUT</incode> to assume that 
            somebody performs that behavior in time frame 1 with probability 1. After the call to provable/3, showProvable/1 
            is used to print a solution to the console; <incode>write</incode> and <incode>fail</incode> are built-in Prolog predicates 
            that print to the console and show all solutions, respectively.
        </p>
        <p>
            The output shows different probabilities of experiencing physical harm. Note that some substances cause more harm at time 6 even if they have 
            lower harm values in the background clauses of the theory; this is because some substances cause more pleasure than others 
            (increasing the likelihood of misuse, and therefore harm).
        </p>
        <p>
            <b>Figure 4. provable/3 Used on the Substance Misuse Example</b>
        </p>
        <p>
            <img src="figure4.png" style="width:100%">
        </p>
        <p>
            Examples in which provable/3 is used are:
            <ul>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/tutorialExamples/tutorialExamples.pl" target="_blank">tutorialExamples.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/substanceMisuseExampleState.pl" target="_blank">substanceMisuseExampleState.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/collinsQuillianExample.pl" target="_blank">collinsQuillianExample.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/planningExample.pl" target="_blank">planningExample.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/substanceMisuseExample.pl" target="_blank">substanceMisuseExample.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/phobiaExample.pl" target="_blank">phobiaExample.pl</a></li>
            </ul>
        </p>

        <h4>6.3. prove/3</h4>
        <p>
            <incode>prove(GOAL, INPUT, RESULT)</incode> finds a proof for <incode>GOAL</incode> given <incode>INPUT</incode> and unifies 
            the result with <incode>RESULT</incode>. In case <incode>GOAL</incode> is not provable, the result is <incode>false</incode>.
            <ul>
                <li><incode>GOAL</incode> should be an atomic formula with constants, variables or functions as arguments.</li>
                <li><incode>INPUT</incode> should be a list of zero or more atomic formulas.</li>
            </ul>
        </p>
        <p>
            <incode>showProof(RESULT, OPTION)</incode> prints the proof obtained from <incode>prove(GOAL, INPUT, RESULT)</incode> to the console.
            <ul>
                <li><incode>OPTION</incode> should be one of the following: <incode>monochrome</incode>, <incode>color</incode>, <incode>lanes</incode>.</li>
            </ul>
        </p>
        <p>
            Note: In case the system of equations in a theory doesn't have a unique solution, prove/3 returns a symbolic solution with all the 
            computations that lead up to the goal.
        </p>
        <p>
            Figure 5 shows a query with prove/3 and its output predicate showProof/2. In the query note that, as in previous examples, 
            underscores (anonymous variables) are used to get "whatever the theory entails for this argument and predicate", and that the particular objects to which the theory 
            is applied are put in <incode>INPUT</incode>. The output shows all the steps that lead up to the conclusion (at the top). Here, the antecedents
            for a given consequent are shown just below the consequent, indented to the right. Goals from the same clause are shown in the same color 
            and level of indentation.
        </p>
        <p>
            <b>Figure 5. prove/3 Used on a Toy Example</b>
        </p>
        <p>
            <img src="figure5.png" style="width:100%">
        </p>
        <p>
            Figure 6 shows a query with prove/3 on the <a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/collinsQuillianExample.pl" target="_blank">
            collinsQuillian example</a>. The goal means "somebody can deduce that a white shark moves in some time frame and with some probability"; by using 
            anonymous variables (underscores) for these arguments we leave it up to prove to find whatever constants the theory entails for this relation.
        </p>
        <p>
            <b>Figure 6. prove/3 Used on the Collins and Quillian Example</b>
        </p>
        <p>
            <img src="figure6.png" style="width:100%">
        </p>
        <p>
            Examples in which prove/3 is used are:
            <ul>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/tutorialExamples/tutorialExamples.pl" target="_blank">tutorialExamples.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/collinsQuillianExample.pl" target="_blank">collinsQuillianExample.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/substanceMisuseExample.pl" target="_blank">substanceMisuseExample.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/substanceMisuseExampleState.pl" target="_blank">substanceMisuseExampleState.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/planningExample.pl" target="_blank">planningExample.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/naturalSelectionExample.pl" target="_blank">naturalSelectionExample.pl</a></li>
            </ul>
        </p>

        <h4>6.4. maxValue/4 and minValue/4</h4>
        <p>
            <incode>maxValue(X, GOAL, INPUT, RESULT)</incode> finds a proof for <incode>GOAL</incode> given <incode>INPUT</incode>, such that the 
            value <incode>X</incode> in <incode>GOAL</incode> is as high as possible; the result is unified with <incode>RESULT</incode>.
            In case <incode>GOAL</incode> is not provable the output is <incode>false</incode>. 
            <ul>
                <li><incode>GOAL</incode> should be an atomic formula with constants, variables or functions as arguments,  where the argument <incode>X</incode> is a numerical variable.</li>
                <li><incode>INPUT</incode> should be a list of zero or more atomic formulas.</li>
            </ul>
            Note: Exogenous numerical variables, i.e. variables that do not appear as dependens in any theory equation, should be unified with a set of numerical constants in the theory or in INPUT.
        </p>
        <p>
            <incode>showMaxValue(RESULT, OPTION)</incode> prints the results obtained from <incode>maxValue(X, GOAL, INPUT, RESULT)</incode> to the console.
            <ul>
                <li><incode>OPTION</incode> should be one of the following: <incode>monochrome</incode>, <incode>color</incode>, <incode>lanes</incode>.</li>
            </ul> 
        </p>
        <p>
            <incode>minValue(X, GOAL, INPUT, RESULT)</incode> and <incode>showMinValue(RESULT, OPTION)</incode> have the same functionality, except that 
            they find an show a proof such that the numerical argument <incode>X</incode> is <i>as low as possible</i>.
        </p>
        <p>
            Figure 7 shows maxValue/4 applied to a toy example. In the theory (to the left) note that we assign a set of alternative values to 
            exogenous numerical variables; i.e. numerical variables that do not appear as dependents in any theory equation. This means that the numerical
            variable associated with profit (<incode>X1</incode>), for example, can take on all values that result from using 0, 5 and 10 in the theory equations.
            In the query, the goal contains the variable <incode>X</incode>. Note that <incode>X</incode> also appears in <incode>maxValue(X, GOAL, INPUT, RESULT)</incode> further down. 
            This tells maxValue/4 that it is the value of <incode>X</incode> we want to maximize.
        </p>
        <p>
            The output shows a proof for the goal, such that the <incode>X</incode> variable in the goal is as high as possible. Note that the proof shows 
            all the constants and numerical computations that lead up to this conclusion.
        </p>
        <p>
            <b>Figure 7. maxValue/4 Used on a Toy Example</b>
        </p>
        <p>
            <img src="figure7.png" style="width:100%">
        </p>
        <p>
            Figure 8 shows an example in which maxValue/4 is applied to <a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/substanceMisuseExample.pl" target="_blank">
            substanceMisuseExample.pl</a>. The goal corresponds to "somebody eats unhealthy at time 6 with probability X".
            In addition to the other prerequisites for the theory (defined in it's INPUT section), <incode>INPUT</incode> contains an atom <incode>misuse(eatUnhealthy)</incode>. This allows 
            the theory to also entail things about this behavior (eating unhealthy was not defined as a misuse behavior in the background clauses).
        </p>
        <p>In the output, the proof contains the values of exogenous variables that maximise the value argument of the goal; these values then 
            propagate in the systems of equations that lead up to the numerical value in the goal.
        </p>
        <p>
            <b>Figure 8. maxValue/4 used  on the Substance Misuse Example</b>
        </p>
        <p>
            <img src="figure8.png" style="width:100%">
        </p>
        <p>
            Examples in which maxValue/4 and minValue/4 are used are:
            <ul>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/tutorialExamples/tutorialExamples.pl" target="_blank">tutorialExamples.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/emotionExample.pl" target="_blank">emotionExample.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/substanceMisuseExample.pl" target="_blank">substanceMisuseExample.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/sourceMemoryExample.pl" target="_blank">sourceMonitoringExample.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/neuropharmacologyExample.pl" target="_blank">neuropharmacologyExample.pl</a></li>
            </ul>
        </p>

        <h4>6.5. incoherence/7</h4>
        <p>
            <incode>incoherence(GOAL1, GOAL2, INPUT, THRESHOLD, X1, X2, RESULT)</incode> checks if <incode>GOAL1</incode> and 
            <incode>GOAL2</incode> differ with respect to their numerical values <incode>X1</incode> and <incode>X2</incode>, 
            more than <incode>THRESHOLD</incode> given <incode>INPUT</incode>. The result is unified with <incode>RESULT</incode>.
            In case there is no incoherence, the output is <incode>false</incode>.
            <ul>
                <li><incode>GOAL1</incode> and <incode>GOAL2</incode> should be atomic formulas that each contain a numerical variable; 
                    for example <incode>X1</incode> and <incode>X2</incode>, respectively.</li>
                    <li><incode>INPUT</incode> should be a list of zero or more atomic formulas.</li>
                    <li><incode>THRESHOLD</incode> should be a number (integer or real).</li>
                    <li><incode>X1</incode> and <incode>X2</incode> are the numerical variables in <incode>GOAL1</incode> and <incode>GOAL2</incode>.</li>
            </ul>
        </p>
        <p>
            <incode>showIncoherence(RESULT, OPTION)</incode> prints the results obtained from <incode>incoherence(INPUT, GOAL1, GOAL2, THRESHOLD, X1, X2, RESULT)</incode> to the console.
            <ul>
                <li><incode>OPTION</incode> should be one of the following: <incode>monochrome</incode>, <incode>color</incode>, <incode>lanes</incode>.</li>
            </ul>
        </p>
        <p>
            Figure 9 shows a toy example with incoherence/7. Note that <incode>GOAL1</incode> and <incode>GOAL2</incode> have the same variables 
            for the first two arguments (<incode>A</incode> and <incode>B</incode>), but that the last value arguments are <incode>X1</incode> and <incode>X2</incode>.
            In this way it is possible to check whether a theory entails that two goals that have the same meaning (represented by <incode>A</incode> and <incode>B</incode>)
            have different probabilities (i.e. an incoherence). Remember that same named variables in a clause have to hold the same constants.
        </p>
        <p>
            <b>Figure 9. incoherence/7 Used on a Toy Example</b>
        </p>
        <p>
            <img src="figure9.png" style="width:100%">
        </p>
        <p>
            Figure 10 shows incoherence/7 applied to <a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/phobiaExample.pl" target="_blank">
            phobiaExample.pl</a>. Note that in <incode>GOAL1</incode> and <incode>GOAL2</incode> the first four arguments contain the same variables; this
            means that both goals have to have the same subject, verb, object and time frame (given that same named variables in a clause have to hold the same constants). 
            The output shows that there is an incoherence in the theory: It entails that the probabilities of fear are different, even if the input is the same.
            The proof shows why this happens. Note that the clause about the negative relation between avoiding an object and encountering an object is involved. 
        </p>
        <p>
            <b>Figure 10. incoherence/7 Used on the Phobia Example</b>
        </p>
        <p>
            <img src="figure10.png" style="width:100%">
        </p>
        <p>
            Examples in which incoherence/7 is used are:
            <ul>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/tutorialExamples/tutorialExamples.pl" target="_blank">tutorialExamples.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/phobiaExample.pl" target="_blank">phobiaExample.pl</a></li>
            </ul>
        </p>

        <h4>6.6 falsifiability/3</h4>
        <p>
            <incode>falsifiability(GOAL, INPUT, RESULT)</incode> counts the number of unique predictions with respect to 
            <incode>GOAL</incode> given <incode>INPUT</incode> and unifies the result with <incode>RESULT</incode>.
            <ul>
                <li><incode>GOAL</incode> should be an atomic formula with constants, variables or functions as arguments.</li>
                <li><incode>INPUT</incode> should be a list of zero or more atomic formulas.</li>
            </ul>
        </p>
        <p>
            <incode>showFalsifiability(RESULT)</incode> prints the results of <incode>falsifiability(GOAL, INPUT, RESULT)</incode> to the console.
        </p>
        <p>
            Consider Figure 11 which shows a toy exaple involving falsifiability/3. In the example there are two subtheories: subTheoryA and subTheoryB.
            The second one is more general because a parent is defined as either a mother or a father. Note that in <incode>q61</incode> and <incode>q62</incode>
            the information in <incode>INPUT</incode> is the same, except that in the first case subTheoryA holds and in the second case 
            subTheoryB holds. The output shows that subTheoryB is more falsifiable because it makes more predictions; i.e. it is a more general theory.
        </p>
        <p>
            <b>Figure 11. falsifiability/3 Used on a Toy Example</b>
        </p>
        <p>
            <img src="figure11.png" style="width:100%">
        </p>
        <p>
            A realistic example is shown in Figure 12, which is based on 
            <a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/distanceExample.pl" target="_blank">distanceExample.pl</a>.
            The goal means "somebody can deduce that some object is beyond some other object at some time with some probability".
            This theory has a recursive part and a non recursive part. In <incode>INPUT</incode> the recursive part is assumed to hold. The output shows that 
            the theory generates 28 predictions. Replacing <incode>source(recursive)</incode> with <incode>source(nonrecursive)</incode> in 
            <incode>INPUT</incode> only generates 13 predictions (not shown). The recursive theory is therefore more falsifiable and general.
        </p>
        <p>
            <b>Figure 12. falsifiability/3 Used on the Distance Example</b>
        </p>
        <p>
            <img src="figure12.png" style="width:100%">
        </p>
        <p>
            Examples in which falsifiability/3 is used are:
            <ul>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/tutorialExamples/tutorialExamples.pl" target="_blank">tutorialExamples.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/distanceExample.pl" target="_blank">distanceExample.pl</a></li>
            </ul>
        </p>

        <h4>6.7. subsumes/5</h4>
        <p>
            <incode>subsumes(SUPERTHEORY, SUBTHEORY, GOAL, INPUT, RESULT)</incode> checks if <incode>SUPERTHEORY</incode>
            subsumes <incode>SUBTHEORY</incode> with respect to <incode>GOAL</incode> given <incode>INPUT</incode> and 
            unifies the result with <incode>RESULT</incode>.
            <ul>
                <li><incode>GOAL</incode> should be an atomic formula with constants, variables or functions as arguments.</li>
                <li><incode>SUPERTHEORY</incode> and <incode>SUBTHEORY</incode> should be atomic formulas. </li>
                <li><incode>INPUT</incode> should be a list of zero or more atomic formulas.</li>
            </ul>
            Note: Clauses that belong to <incode>SUPERTHEORY</incode> should have <incode>SUPERTHEORY</incode> in their antecedent; 
            clauses that belong to <incode>SUBTHEORY</incode> should have <incode>SUBTHEORY</incode> in their antecedent. 
            <incode>INPUT</incode> should not contain <incode>SUPERTHEORY</incode> and <incode>SUBTHEORY</incode>.
        </p>
        <p>
            <incode>showSubsumes(RESULT)</incode> prints the results from <incode>subsumes(SUPERTHEORY, SUBTHEORY, GOAL, INPUT, RESULT)</incode> to the console.
        </p>
        <p>
            Figure 13 shows a toy example in which subsumes/5 is used. The goal means "the objects for which the anchestor relation can be deduced".
            Theory B subsumes theory A because in theory B, an ancestor is either somebody's parent or somebody's grandparent.
        </p>
        <p>
            <b>Figure 13. subsumes/5 Used on a Toy Example</b>
        </p>
        <p>
            <img src="figure13.png" style="width:100%">
        </p>
        <p>
            A realistic example is shown in Figure 14, which is based on 
            <a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/distanceExample.pl" target="_blank">distanceExample.pl</a>. 
            The goal corresponds to "somebody can deduce that some object is beyond some other object at some time with some probability".
            The clauses of this theory either contain an atom <incode>source(recursive)</incode> or <incode>source(nonrecursive)</incode>. In the query 
            these are used as arguments to subsumes/5 to find out if the recursive theory subsumes the non recursive one. 
            As shown in the output, the recursive theory indeed subsumes the non recursive one; i.e. all the clauses in the non recursive theory also 
            exist in the recursive one.
        </p>
        <p>
            <b>Figure 14. subsumes/5 Used on the Distance Example</b>
        </p>
        <p>
            <img src="figure14.png" style="width:100%">
        </p>
        <p>
            Examples in which subsumes/5 is used are:
            <ul>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/tutorialExamples/tutorialExamples.pl" target="_blank">tutorialExamples.pl</a></li>
                <li><a href="https://github.com/JeanChristopheRohner/theory-toolbox-2/blob/main/theoryExamples/distanceExample.pl" target="_blank">distanceExample.pl</a></li>
            </ul>
        </p>


        <!-- References -->

        <h3>References</h3>
        <ul>
            <li>Bratko, I. (2001). Prolog programming for artificial intelligence. Pearson education.</li>
            <li>Popper, K. R. (1972). The logic of scientific discovery. Hutchinson.</li>
            <li>Rohner, J. C. & Kjellerstrand, H. (2021). Using logic programming for theory representation and inference. New Ideas in Psychology, 6, 100838.</li>
            <li>Wielemaker, J., Schrijvers, T., Triska, M., & Lager, T. (2010). Swi-prolog. arXiv preprint arXiv:1011.5332. </li>
        </ul>


    </div>

  
</div>
  

<!-- Footer -->

<footer class="w3-container w3-padding-32 w3-light-grey w3-center">
    <p>© Jean-Christophe Rohner 2019, 2020</p>
    <a href="#" class="w3-button w3-black w3-margin"><i class="fa fa-arrow-up w3-margin-right"></i>To the top</a>
    <p>Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-text-green">w3.css</a></p>
</footer>
  




</body>
</html>